{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the BSP correction factors for all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import important packages and set up file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import readsav\n",
    "\n",
    "from read import read_NX2\n",
    "import plot\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lusoria 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat0651 = read_NX2('../data/2006/20060623fifth-day-no-sail.csv', \n",
    "                   origin = (49.0164, 12.0285))\n",
    "dat0661 = read_NX2('../data/2006/20060624sixth-day-with-sail.csv', \n",
    "                   origin = (49.0164, 12.0285))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schwaller = readsav('../data/2006/stromgeschwindigkeit.sav')['strom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = plt.quiver(schwaller['x'][0], schwaller['y'][0], schwaller['vx'][0], schwaller['vy'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot.speeds(dat0661)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing how good the blue and the orange line agree in the plot above,\n",
    "I think we can say that the BSP correction factor must be almost exactly one. In fact,\n",
    "if I remember correctly, we actually took the value for the correction that the NX2 suggested and \n",
    "accepted them, thus making the correction factor 1 for the later days.\n",
    "\n",
    "Below is a plot_course plot, but I also don't see any anomalies there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot.course(dat0661, scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, ind, ax = plot.fit_BSP(dat0661)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, that is basically all consistent with a correction factor of $0.94 \\approx 1$ (within 10% - \n",
    "I don't think that we'll get much better than that).\n",
    "\n",
    "Now, let's do the same experiment on the other day with sailing data in 2006. All dates without\n",
    "sailing need not be calibrated at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, ind, ax = plot.fit_BSP(dat0651)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, $\\beta = 0.8$  which is significantly less than the other day, but after the cuts there\n",
    "is actually very little data left anyway. Here, I show the data that was not used in the fit\n",
    "because is was taken during a time of gusty wind, in unfavourable wind angles etc. (see the\n",
    "documentation of the fitting procedure for details) and most of this data also indicates a \n",
    "higher value for $\\beta$ than fit. Thus, I conclude, that the values of $\\beta$ might well\n",
    "be compatible with what I have seen for the other day and I use 0.95 as the correction factor for all\n",
    "2006 data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Victoria: Data from 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filelist = glob.glob('../data/2008/08*csv')\n",
    "filelist.sort()\n",
    "\n",
    "dat08 = [read_NX2(f) for f in filelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = course(dat08[5], scale=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks OK to me. At least, no errors are immidiately obvious, i.e. the rowing times line up with the times of the trip, sailing is in between rowing sections etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,10))\n",
    "for i, data in enumerate(dat08):\n",
    "    ax = fig.add_subplot(3,7,i+1)\n",
    "    a, ind, ax = plot.fit_BSP(data, ax=ax)\n",
    "    ax.set_title(f'{i}: {a:5.3f}')\n",
    "    ax.plot(plt.xlim(), np.array([1.15]) * plt.xlim(), 'g', label = 'm = 1.15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the SOG on the x-axis and the BSP on the y-axis for all days in 2008. Black dots are used in the fit, yellow dots are rejected, because e.g. they are recorded at time when the wind speed or the direction of the boat changed significantly or when the course-over-ground (COG) and the compass course (HDC) disagree. If COG and HDC are parallel and there is no current (as expected on a lake), then SOG and BSP should have the same value. If there is an angle between COG and HDC, then we boat is drifted sideways to some degree, which causes the BSP to measure only one component of the velocity vector. This differece is the drift, one of the parameters we seek to constrain with those measurements.\n",
    "\n",
    "\n",
    "The green line the best fit to the dataset from each day; the numerical value for $\\beta$, the slope of the line, is show in the title of each panel. The red line plotted in all figures is a line with $\\beta = 1.15$, which I propose to take for all measurements in 2008. In most plots, the fit value is virtually indistinguishable from 1.15, those with strong disagreements have either a very low number of datapoints (e.g. second and forth plot in last row) or the pattern of the black dots looks in some way inconsistent (first and third plot in first row).\n",
    "\n",
    "The cloud of black points is always much tighther \n",
    "\n",
    "Below, I pick the third dataset with shows $\\beta = 1.0\\:$ and look at it in some more detail, because I suspect that this is a case where the log was not fully submerged, possibly one of those days with a lot of guests or a film crew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot.course(dat08[3], scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot.speeds(dat08[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the SOG-BSP plot there is this off group of black dots that have SOG$ > 3.3$, but relatively low BSP. Let's find out what happened there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind33 = data.SOG > 3.3\n",
    "ind33.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time period in questions is only 70 s long, the BSP here is lower than it should be. During this time, the ship moved into a wind, going in a very tight loop. While I cannot reproduce exac\n",
    "tly, what happened here, it is obvious form the SOG-BSP diagram that the conversion factor in this phase must be different from the usual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lusoria 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob.glob('../data/2011/2011*csv')\n",
    "filelist.sort()\n",
    "\n",
    "dat11 = [read_NX2(f) for f in filelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "for i, data in enumerate(dat11):\n",
    "    ax = fig.add_subplot(5, 7 , i+1)\n",
    "    a, ind, ax = plot.fit_BSP(data, ax=ax)\n",
    "    ax.set_title(f'{i}: {a:5.3f}')\n",
    "    ax.plot(plt.xlim(), np.array([0.87]) * plt.xlim(), 'y', label = 'm = 0.87')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expect for the first dataset (number 0), all datasets are beautifully consistent with $\\beta = 0.87\\;$. In all cases, the cloud of black points is extremly narrow. Some of the datasets are teken with the mast set, some are taken without, but apparently that makes no difference for the fitting of $\\beta\\;$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Victoria 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob.glob('../data/2012/2012*csv')\n",
    "filelist.sort()\n",
    "\n",
    "dat12 = [read_NX2(f) for f in filelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 4))\n",
    "for i, data in enumerate(dat12):\n",
    "    ax = fig.add_subplot(1, 7 , i+1)\n",
    "    a, ind, ax = plot.fit_BSP(data, ax=ax)\n",
    "    ax.set_title(f'{i}: {a:5.3f}')\n",
    "    ax.plot(plt.xlim(), np.array([0.87]) * plt.xlim(), 'y', label = 'm = 0.87')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same $\\beta = 0.87\\:$ that worked well in 2011 is again a very good fit to the data in 2012. This is not surprising, since we used exactly the same methods of fixing the log, in fact we can take that as confimations that the log is put in place in a very reproducable manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, from this analysis, we see that the following correction factors should be used for all the following analysis::\n",
    "\n",
    "- Lusoria Regina 2006: $\\beta = 0.95$\n",
    "- Victoria 2008: $\\beta = 1.18$\n",
    "- Lusoria Rhenana 2011 and 2012: $\\beta = 0.87$"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:NX2]",
   "language": "python",
   "name": "conda-env-NX2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
